package com.khoipd8.educationchatbot.service;

import com.khoipd8.educationchatbot.entity.University;
import com.khoipd8.educationchatbot.entity.Program;

import org.springframework.stereotype.Service;
import lombok.extern.slf4j.Slf4j;
import java.util.*;
import java.util.stream.Collectors;
import java.util.regex.Pattern;
import java.util.regex.Matcher;

@Service
@Slf4j
public class EnhancedRAGService {
    
    // SEMANTIC SEARCH - Hi·ªÉu √Ω nghƒ©a c√¢u h·ªèi
    private final Map<String, List<String>> semanticKeywords = new HashMap<>();
    
    // QUERY PREPROCESSING - Chu·∫©n h√≥a c√¢u h·ªèi
    private final Map<String, String> queryNormalization = new HashMap<>();
    
    // CONTEXT ENRICHMENT - B·ªï sung th√¥ng tin li√™n quan
    private final Map<String, List<String>> relatedTopics = new HashMap<>();
    
    public EnhancedRAGService() {
        initializeSemanticMaps();
    }
    
    /**
     * üß† SMART QUERY UNDERSTANDING
     */
    public QueryContext analyzeQuery(String userQuery) {
        String normalizedQuery = normalizeQuery(userQuery);
        QueryIntent intent = detectIntent(normalizedQuery);
        List<String> entities = extractEntities(normalizedQuery);
        List<String> keywords = extractEnhancedKeywords(normalizedQuery);
        
        log.info("üß† Query Analysis - Intent: {}, Entities: {}, Keywords: {}", 
                intent, entities, keywords);
        
        return new QueryContext(normalizedQuery, intent, entities, keywords);
    }
    
    /**
     * üìö ENHANCED CHUNK CREATION - T·∫°o chunks th√¥ng minh h∆°n
     */
    public List<DocumentChunk> createEnhancedChunks(University university) {
        List<DocumentChunk> chunks = new ArrayList<>();
        
        // 1. University overview chunk v·ªõi metadata
        chunks.add(createUniversityOverviewChunk(university));
        
        // 2. Programs chunks theo t·ª´ng category
        chunks.addAll(createProgramChunksByCategory(university));
        
        // 3. Admission requirements chunk
        chunks.add(createAdmissionRequirementsChunk(university));
        
        // 4. Statistical summary chunk
        chunks.add(createStatisticalSummaryChunk(university));
        
        return chunks;
    }
    
    /**
     * üéØ INTELLIGENT SEARCH - T√¨m ki·∫øm th√¥ng minh
     */
    public List<DocumentChunk> intelligentSearch(QueryContext queryContext, List<DocumentChunk> allChunks, int limit) {
        Map<DocumentChunk, Double> chunkScores = new HashMap<>();
        
        for (DocumentChunk chunk : allChunks) {
            double score = calculateIntelligentScore(queryContext, chunk);
            if (score > 0.1) { // Threshold for relevance
                chunkScores.put(chunk, score);
            }
        }
        
        return chunkScores.entrySet().stream()
                .sorted(Map.Entry.<DocumentChunk, Double>comparingByValue().reversed())
                .limit(limit)
                .map(Map.Entry::getKey)
                .collect(Collectors.toList());
    }
    
    /**
     * üí° CONTEXT-AWARE RESPONSE GENERATION
     */
    public String generateContextualPrompt(QueryContext queryContext, List<DocumentChunk> chunks) {
        StringBuilder prompt = new StringBuilder();
        
        // 1. Specify the role based on query intent
        prompt.append(getRoleSpecificPrompt(queryContext.getIntent()));
        
        // 2. Add relevant context with structure
        prompt.append("\n\nTh√¥ng tin c√≥ s·∫µn:\n");
        for (DocumentChunk chunk : chunks) {
            prompt.append(formatChunkForPrompt(chunk, queryContext));
        }
        
        // 3. Add specific instructions based on query type
        prompt.append(getQuerySpecificInstructions(queryContext));
        
        // 4. Add the user question with emphasis
        prompt.append(String.format("\n\nC√¢u h·ªèi c·∫ßn tr·∫£ l·ªùi: \"%s\"", queryContext.getOriginalQuery()));
        
        return prompt.toString();
    }
    
    // ===== PRIVATE HELPER METHODS =====
    
    private void initializeSemanticMaps() {
        // Semantic keyword mapping
        semanticKeywords.put("admission_scores", Arrays.asList(
            "ƒëi·ªÉm chu·∫©n", "ƒëi·ªÉm x√©t tuy·ªÉn", "ƒëi·ªÉm ƒë·∫ßu v√†o", "benchmark", "cutoff score", 
            "score", "ƒëi·ªÉm", "x√©t tuy·ªÉn", "tuy·ªÉn sinh"
        ));
        
        semanticKeywords.put("programs", Arrays.asList(
            "ng√†nh h·ªçc", "chuy√™n ng√†nh", "program", "major", "course", "h·ªçc", "ƒë√†o t·∫°o",
            "curriculum", "ng√†nh", "chuy√™n", "training"
        ));
        
        semanticKeywords.put("universities", Arrays.asList(
            "tr∆∞·ªùng ƒë·∫°i h·ªçc", "university", "college", "tr∆∞·ªùng", "ƒë·∫°i h·ªçc", "h·ªçc vi·ªán",
            "vi·ªán", "school", "institution"
        ));
        
        semanticKeywords.put("requirements", Arrays.asList(
            "ƒëi·ªÅu ki·ªán", "y√™u c·∫ßu", "requirement", "criteria", "qualification", 
            "prerequisite", "tuy·ªÉn", "nh·∫≠n"
        ));
        
        semanticKeywords.put("fees", Arrays.asList(
            "h·ªçc ph√≠", "fee", "tuition", "cost", "price", "ph√≠", "ti·ªÅn", "chi ph√≠"
        ));
        
        // Query normalization
        queryNormalization.put("cntt", "c√¥ng ngh·ªá th√¥ng tin");
        queryNormalization.put("it", "c√¥ng ngh·ªá th√¥ng tin");
        queryNormalization.put("cs", "khoa h·ªçc m√°y t√≠nh");
        queryNormalization.put("bk", "b√°ch khoa");
        queryNormalization.put("dhbk", "ƒë·∫°i h·ªçc b√°ch khoa");
        queryNormalization.put("ngo·∫°i th∆∞∆°ng", "ƒë·∫°i h·ªçc ngo·∫°i th∆∞∆°ng");
        
        // Related topics
        relatedTopics.put("admission_scores", Arrays.asList("requirements", "programs", "subject_combinations"));
        relatedTopics.put("programs", Arrays.asList("admission_scores", "fees", "universities"));
        relatedTopics.put("fees", Arrays.asList("programs", "universities"));
    }
    
    private String normalizeQuery(String query) {
        String normalized = query.toLowerCase().trim();
        
        // Apply normalization mappings
        for (Map.Entry<String, String> entry : queryNormalization.entrySet()) {
            normalized = normalized.replace(entry.getKey(), entry.getValue());
        }
        
        // Clean up extra spaces
        normalized = normalized.replaceAll("\\s+", " ");
        
        return normalized;
    }
    
    private QueryIntent detectIntent(String query) {
        if (containsAnyKeyword(query, semanticKeywords.get("admission_scores"))) {
            return QueryIntent.GET_ADMISSION_SCORES;
        } else if (containsAnyKeyword(query, semanticKeywords.get("programs"))) {
            return QueryIntent.GET_PROGRAMS;
        } else if (containsAnyKeyword(query, semanticKeywords.get("fees"))) {
            return QueryIntent.GET_FEES;
        } else if (containsAnyKeyword(query, semanticKeywords.get("requirements"))) {
            return QueryIntent.GET_REQUIREMENTS;
        } else if (containsAnyKeyword(query, semanticKeywords.get("universities"))) {
            return QueryIntent.GET_UNIVERSITY_INFO;
        } else if (query.contains("so s√°nh") || query.contains("compare")) {
            return QueryIntent.COMPARE;
        } else if (query.contains("t∆∞ v·∫•n") || query.contains("g·ª£i √Ω") || query.contains("suggest")) {
            return QueryIntent.ADVISE;
        }
        
        return QueryIntent.GENERAL_INFO;
    }
    
    private List<String> extractEntities(String query) {
        List<String> entities = new ArrayList<>();
        
        // Extract university names
        Pattern universityPattern = Pattern.compile("(b√°ch khoa|ngo·∫°i th∆∞∆°ng|kinh t·∫ø|y khoa|s∆∞ ph·∫°m|c√¥ng ngh·ªá|n√¥ng nghi·ªáp)", Pattern.CASE_INSENSITIVE);
        Matcher universityMatcher = universityPattern.matcher(query);
        while (universityMatcher.find()) {
            entities.add("university:" + universityMatcher.group(1));
        }
        
        // Extract major names
        Pattern majorPattern = Pattern.compile("(c√¥ng ngh·ªá th√¥ng tin|y khoa|lu·∫≠t|kinh t·∫ø|qu·∫£n tr·ªã|t√†i ch√≠nh|marketing)", Pattern.CASE_INSENSITIVE);
        Matcher majorMatcher = majorPattern.matcher(query);
        while (majorMatcher.find()) {
            entities.add("major:" + majorMatcher.group(1));
        }
        
        // Extract years
        Pattern yearPattern = Pattern.compile("(202[0-9]|201[0-9])");
        Matcher yearMatcher = yearPattern.matcher(query);
        while (yearMatcher.find()) {
            entities.add("year:" + yearMatcher.group(1));
        }
        
        // Extract scores
        Pattern scorePattern = Pattern.compile("(\\d{1,2}[\\.,]\\d{1,2}|\\d{2,3})\\s*(ƒëi·ªÉm|point)");
        Matcher scoreMatcher = scorePattern.matcher(query);
        while (scoreMatcher.find()) {
            entities.add("score:" + scoreMatcher.group(1));
        }
        
        return entities;
    }
    
    private List<String> extractEnhancedKeywords(String query) {
        List<String> keywords = new ArrayList<>();
        
        // Add all semantic keywords that match
        for (Map.Entry<String, List<String>> entry : semanticKeywords.entrySet()) {
            for (String keyword : entry.getValue()) {
                if (query.toLowerCase().contains(keyword.toLowerCase())) {
                    keywords.add(keyword);
                }
            }
        }
        
        // Add important words (noun phrases, adjectives)
        String[] words = query.split("\\s+");
        for (String word : words) {
            if (word.length() > 3 && !isStopWord(word)) {
                keywords.add(word.toLowerCase());
            }
        }
        
        return keywords.stream().distinct().collect(Collectors.toList());
    }
    
    private DocumentChunk createUniversityOverviewChunk(University university) {
        StringBuilder content = new StringBuilder();
        content.append(String.format("T·ªîNG QUAN TR∆Ø·ªúNG: %s (%s)\n", university.getName(), university.getCode()));
        content.append(String.format("ƒê·ªãa ƒëi·ªÉm: %s\n", university.getLocation() != null ? university.getLocation() : "Ch∆∞a x√°c ƒë·ªãnh"));
        content.append(String.format("Lo·∫°i h√¨nh: %s\n", university.getType() != null ? university.getType() : "C√¥ng l·∫≠p"));
        content.append(String.format("S·ªë ng√†nh ƒë√†o t·∫°o: %d\n", university.getPrograms().size()));
        
        // Add some statistics
        if (!university.getPrograms().isEmpty()) {
            OptionalDouble avgScore = university.getPrograms().stream()
                    .filter(p -> p.getBenchmarkScore2024() != null)
                    .mapToDouble(p -> parseScore(String.valueOf(p.getBenchmarkScore2024())))
                    .filter(score -> score > 0)
                    .average();
            
            if (avgScore.isPresent()) {
                content.append(String.format("ƒêi·ªÉm chu·∫©n trung b√¨nh: %.2f\n", avgScore.getAsDouble()));
            }
        }
        
        return new DocumentChunk(
            "overview_" + university.getCode(),
            content.toString(),
            "university_overview",
            university.getCode(),
            university.getName() + " - T·ªïng quan"
        );
    }
    
    private List<DocumentChunk> createProgramChunksByCategory(University university) {
        List<DocumentChunk> chunks = new ArrayList<>();
        
        // Group programs by category
        Map<String, List<Program>> programsByCategory = university.getPrograms().stream()
                .collect(Collectors.groupingBy(this::categorizeProgramName));
        
        for (Map.Entry<String, List<Program>> entry : programsByCategory.entrySet()) {
            StringBuilder content = new StringBuilder();
            content.append(String.format("NH√ìM NG√ÄNH %s T·∫†I %s:\n", entry.getKey().toUpperCase(), university.getName()));
            
            for (Program program : entry.getValue()) {
                content.append(String.format("- %s: ƒêi·ªÉm 2024: %s, T·ªï h·ª£p: %s\n",
                    program.getName(),
                    program.getBenchmarkScore2024() != null ? program.getBenchmarkScore2024() : "Ch∆∞a c√≥",
                    program.getSubjectCombination() != null ? program.getSubjectCombination() : "Ch∆∞a x√°c ƒë·ªãnh"
                ));
            }
            
            chunks.add(new DocumentChunk(
                "category_" + university.getCode() + "_" + entry.getKey(),
                content.toString(),
                "program_category",
                university.getCode(),
                university.getName() + " - " + entry.getKey()
            ));
        }
        
        return chunks;
    }
    
    private DocumentChunk createAdmissionRequirementsChunk(University university) {
        StringBuilder content = new StringBuilder();
        content.append(String.format("ƒêI·ªÄU KI·ªÜN X√âT TUY·ªÇN - %s:\n", university.getName()));
        
        // Extract unique subject combinations
        Set<String> subjectCombinations = university.getPrograms().stream()
                .map(Program::getSubjectCombination)
                .filter(Objects::nonNull)
                .collect(Collectors.toSet());
        
        content.append("C√°c t·ªï h·ª£p x√©t tuy·ªÉn:\n");
        for (String combination : subjectCombinations) {
            content.append(String.format("- %s\n", combination));
        }
        
        // Add score ranges
        DoubleSummaryStatistics scoreStats = university.getPrograms().stream()
                .filter(p -> p.getBenchmarkScore2024() != null)
                .mapToDouble(p -> parseScore(String.valueOf(p.getBenchmarkScore2024())))
                .filter(score -> score > 0)
                .summaryStatistics();
        
        if (scoreStats.getCount() > 0) {
            content.append(String.format("ƒêi·ªÉm chu·∫©n t·ª´: %.2f ƒë·∫øn %.2f\n", scoreStats.getMin(), scoreStats.getMax()));
        }
        
        return new DocumentChunk(
            "requirements_" + university.getCode(),
            content.toString(),
            "admission_requirements",
            university.getCode(),
            university.getName() + " - ƒêi·ªÅu ki·ªán x√©t tuy·ªÉn"
        );
    }
    
    private DocumentChunk createStatisticalSummaryChunk(University university) {
        StringBuilder content = new StringBuilder();
        content.append(String.format("TH·ªêNG K√ä TUY·ªÇN SINH - %s:\n", university.getName()));
        
        Map<String, Long> programCount = university.getPrograms().stream()
                .collect(Collectors.groupingBy(this::categorizeProgramName, Collectors.counting()));
        
        content.append("S·ªë l∆∞·ª£ng ng√†nh theo lƒ©nh v·ª±c:\n");
        for (Map.Entry<String, Long> entry : programCount.entrySet()) {
            content.append(String.format("- %s: %d ng√†nh\n", entry.getKey(), entry.getValue()));
        }
        
        return new DocumentChunk(
            "stats_" + university.getCode(),
            content.toString(),
            "statistical_summary",
            university.getCode(),
            university.getName() + " - Th·ªëng k√™"
        );
    }
    
    private double calculateIntelligentScore(QueryContext queryContext, DocumentChunk chunk) {
        double score = 0.0;
        
        // 1. Intent-based scoring
        score += calculateIntentScore(queryContext.getIntent(), chunk);
        
        // 2. Entity matching
        score += calculateEntityScore(queryContext.getEntities(), chunk);
        
        // 3. Keyword relevance
        score += calculateKeywordScore(queryContext.getKeywords(), chunk);
        
        // 4. Chunk type relevance
        score += calculateChunkTypeScore(queryContext.getIntent(), chunk.getType());
        
        return score;
    }
    
    private String getRoleSpecificPrompt(QueryIntent intent) {
        switch (intent) {
            case GET_ADMISSION_SCORES:
                return "B·∫°n l√† chuy√™n gia t∆∞ v·∫•n tuy·ªÉn sinh, chuy√™n v·ªÅ ƒëi·ªÉm chu·∫©n v√† x√©t tuy·ªÉn ƒë·∫°i h·ªçc.";
            case GET_PROGRAMS:
                return "B·∫°n l√† c·ªë v·∫•n h·ªçc thu·∫≠t, am hi·ªÉu v·ªÅ c√°c ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o ƒë·∫°i h·ªçc.";
            case GET_FEES:
                return "B·∫°n l√† t∆∞ v·∫•n vi√™n t√†i ch√≠nh gi√°o d·ª•c, hi·ªÉu r√µ v·ªÅ h·ªçc ph√≠ v√† chi ph√≠ h·ªçc t·∫≠p.";
            case COMPARE:
                return "B·∫°n l√† chuy√™n gia ph√¢n t√≠ch so s√°nh c√°c l·ª±a ch·ªçn gi√°o d·ª•c.";
            case ADVISE:
                return "B·∫°n l√† c·ªë v·∫•n h∆∞·ªõng nghi·ªáp, gi√∫p h·ªçc sinh ch·ªçn ng√†nh v√† tr∆∞·ªùng ph√π h·ª£p.";
            default:
                return "B·∫°n l√† tr·ª£ l√Ω t∆∞ v·∫•n tuy·ªÉn sinh ƒë·∫°i h·ªçc th√¥ng minh v√† nhi·ªát t√¨nh.";
        }
    }
    
    // Additional helper methods...
    private boolean containsAnyKeyword(String text, List<String> keywords) {
        return keywords.stream().anyMatch(keyword -> text.toLowerCase().contains(keyword.toLowerCase()));
    }
    
    private boolean isStopWord(String word) {
        Set<String> stopWords = Set.of("l√†", "c·ªßa", "v√†", "c√≥", "ƒë∆∞·ª£c", "trong", "v·ªõi", "ƒë·ªÉ", "v·ªÅ", "t·ª´", "bao", "nhi√™u", "g√¨", "n√†o", "nh∆∞", "th·∫ø");
        return stopWords.contains(word.toLowerCase());
    }
    
    private String categorizeProgramName(Program program) {
        String name = program.getName().toLowerCase();
        if (name.contains("c√¥ng ngh·ªá") || name.contains("k·ªπ thu·∫≠t") || name.contains("cntt")) {
            return "C√¥ng ngh·ªá - K·ªπ thu·∫≠t";
        } else if (name.contains("kinh t·∫ø") || name.contains("qu·∫£n tr·ªã") || name.contains("t√†i ch√≠nh")) {
            return "Kinh t·∫ø - Qu·∫£n tr·ªã";
        } else if (name.contains("y") || name.contains("d∆∞·ª£c") || name.contains("ƒëi·ªÅu d∆∞·ª°ng")) {
            return "Y - D∆∞·ª£c - S·ª©c kh·ªèe";
        } else if (name.contains("s∆∞ ph·∫°m") || name.contains("gi√°o d·ª•c")) {
            return "S∆∞ ph·∫°m - Gi√°o d·ª•c";
        } else if (name.contains("lu·∫≠t") || name.contains("ph√°p l√Ω")) {
            return "Lu·∫≠t - Ch√≠nh tr·ªã";
        } else {
            return "Kh√°c";
        }
    }
    
    private double parseScore(String scoreStr) {
        try {
            return Double.parseDouble(scoreStr.replace(",", "."));
        } catch (NumberFormatException e) {
            return 0.0;
        }
    }
    
    // Implement other scoring methods...
    private double calculateIntentScore(QueryIntent intent, DocumentChunk chunk) {
        // Implementation details for intent-based scoring
        return 0.5; // Placeholder
    }
    
    private double calculateEntityScore(List<String> entities, DocumentChunk chunk) {
        // Implementation details for entity matching
        return 0.3; // Placeholder
    }
    
    private double calculateKeywordScore(List<String> keywords, DocumentChunk chunk) {
        // Implementation details for keyword relevance
        return 0.2; // Placeholder
    }
    
    private double calculateChunkTypeScore(QueryIntent intent, String chunkType) {
        // Implementation details for chunk type relevance
        return 0.1; // Placeholder
    }
    
    private String formatChunkForPrompt(DocumentChunk chunk, QueryContext queryContext) {
        return String.format("[%s] %s\n", chunk.getType().toUpperCase(), chunk.getContent());
    }
    
    private String getQuerySpecificInstructions(QueryContext queryContext) {
        switch (queryContext.getIntent()) {
            case GET_ADMISSION_SCORES:
                return "\n\nH√£y t·∫≠p trung v√†o th√¥ng tin ƒëi·ªÉm chu·∫©n, t·ªï h·ª£p x√©t tuy·ªÉn v√† c√°c y√™u c·∫ßu tuy·ªÉn sinh.";
            case COMPARE:
                return "\n\nH√£y so s√°nh m·ªôt c√°ch kh√°ch quan v√† cung c·∫•p b·∫£ng so s√°nh r√µ r√†ng.";
            case ADVISE:
                return "\n\nH√£y ƒë∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ, th·ª±c t·∫ø v√† ph√π h·ª£p v·ªõi ho√†n c·∫£nh h·ªçc sinh.";
            default:
                return "\n\nH√£y tr·∫£ l·ªùi ch√≠nh x√°c, ƒë·∫ßy ƒë·ªß v√† d·ªÖ hi·ªÉu.";
        }
    }
    
    // Inner classes
    public static class QueryContext {
        private final String originalQuery;
        private final QueryIntent intent;
        private final List<String> entities;
        private final List<String> keywords;
        
        public QueryContext(String originalQuery, QueryIntent intent, List<String> entities, List<String> keywords) {
            this.originalQuery = originalQuery;
            this.intent = intent;
            this.entities = entities;
            this.keywords = keywords;
        }
        
        // Getters
        public String getOriginalQuery() { return originalQuery; }
        public QueryIntent getIntent() { return intent; }
        public List<String> getEntities() { return entities; }
        public List<String> getKeywords() { return keywords; }
    }
    
    public enum QueryIntent {
        GET_ADMISSION_SCORES,
        GET_PROGRAMS,
        GET_UNIVERSITY_INFO,
        GET_REQUIREMENTS,
        GET_FEES,
        COMPARE,
        ADVISE,
        GENERAL_INFO
    }
    
    // DocumentChunk class (reuse from existing code)
    public static class DocumentChunk {
        private String id, content, type, universityCode, title;
        
        public DocumentChunk(String id, String content, String type, String universityCode, String title) {
            this.id = id;
            this.content = content;
            this.type = type;
            this.universityCode = universityCode;
            this.title = title;
        }
        
        // Getters
        public String getId() { return id; }
        public String getContent() { return content; }
        public String getType() { return type; }
        public String getUniversityCode() { return universityCode; }
        public String getTitle() { return title; }
    }
}